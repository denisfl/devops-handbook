# День 4. Сети и Масштабирование

[tools] [devops] [network] [nginx]

Работа DevOps-инженера часто сводится к одному: обеспечить доставку сетевого пакета из точки А в точку Б.
Понимание того, как течет "цифровая кровь" по венам интернета, отличает инженера от "эникейщика".

---

## Путешествие Пакнета (OSI Model)

Давайте демистифицируем стек TCP/IP, используя уровни модели OSI.

1.  **L3 (Сетевой уровень)**: **IP-адрес**. Это уникальный адрес здания. `192.168.1.5`. Маршрутизаторы (Routers) работают здесь. Они знают, куда перекинуть пакет, чтобы он стал ближе к цели.
2.  **L4 (Транспортный уровень)**: **TCP/UDP Порт**. Это номер квартиры в здании. Веб-сервер Nginx живет в квартире №80. SSH — в №22.
3.  **L7 (Прикладной уровень)**: **HTTP/FTP**. Это язык общения. "Привет, дай мне файл index.html".

### Язык общения: TCP vs UDP
На транспортном уровне (L4) у нас есть два фундаментальных подхода к передаче данных.

**TCP (Transmission Control Protocol): Надежность любой ценой**
Это протокол с установлением соединения.
1.  **Three-Way Handshake**: Прежде чем передать хоть байт полезной информации, клиент и сервер должны пожать руки. (SYN -> SYN-ACK -> ACK). Это создает задержку (Latency).
2.  **Guaranteed Delivery**: Если пакет потерялся в пути, получатель не пришлет подтверждения (ACK), и отправитель вышлет пакет снова.
3.  **Flow Control**: TCP автоматически замедлится, если получатель не успевает обрабатывать данные.
*Итог*: Весь надежный веб (HTTP, SMTP, SSH) построен на TCP. Мы платим скоростью за гарантию.

**UDP (User Datagram Protocol): Скорость ветра**
Это "выстрелил и забыл". Никаких рукопожатий. Никаких гарантий доставки. Никакого порядка пакетов.
*Зачем это нужно?*
В видеозвонке (Zoom) вам не важно, что один пиксель потерялся 5 секунд назад. Вам важно, чтобы видео не зависало. Ожидание переотправки пакета убило бы реалтайм. Поэтому стриминг, DNS и онлайн-игры используют UDP.

---

## Безопасность: HTTPS и TLS

В современном вебе **HTTP** (открытый текст) — это моветон. Провайдер, сосед по Wi-Fi или хакер могут прочитать ваши пароли.
**HTTPS** = HTTP + **TLS** (Transport Layer Security).

### Как работает TLS Handshake?
Когда вы заходите на `https://bank.com`, происходит магия:
1.  **Client Hello**: Браузер говорит: "Привет, я умею шифровать алгоритмами А и Б".
2.  **Server Hello**: Сервер выбирает алгоритм и присылает свой **Сертификат**.
3.  **Validation**: Браузер проверяет Сертификат. Он подписан доверенным Центром Сертификации (CA)? Срок годности не истек?
4.  **Key Exchange**: Браузер и Сервер договариваются об общем *сессионном ключе*.
5.  Всё дальнейшее общение шифруется этим ключом. Даже если пакет перехватят, увидят только мусор.

---

## Масштабирование (Scaling)

Представьте, что вы открыли магазин на одном сервере. В "Черную пятницу" пришло 100 000 человек. Сервер упал.

1.  **Vertical Scaling (Scale Up)**: Купить сервер мощнее (больше CPU/RAM).
    *   *Минус*: Дорого и есть физический предел.
2.  **Horizontal Scaling (Scale Out)**: Поставить 10 серверов поменьше.
    *   *Плюс*: Бесконечное масштабирование.
    *   *Проблема*: Куда стучаться пользователю?

### Load Balancer (Балансировщик)
Это регулировщик (Nginx, HAProxy), который стоит перед кластером.
*   **L4 Balancer**: Тупо пересылает пакеты (смотрит только на IP/Port). Очень быстрый.
*   **L7 Balancer**: Читает содержимое (URL, Cookies). Может отправить `/api` на один сервер, а `/images` на другой.

---

## Практика

### 1. Анатомия запроса c Curl
Браузер скрывает от нас детали. Инженеры используют `curl`.
Посмотрим на TLS Handshake и заголовки:
```bash
curl -v https://google.com
```
Вы увидите:
*   `* Connected to google.com` (TCP Handshake)
*   `* SSL connection using TLSv1.3` (TLS Handshake)
*   `* Server certificate: GTS CA` (Проверка сертификата)
*   `> GET / HTTP/2` (L7 Запрос)

### 2. DNS раскопки
Попробуйте узнать, кто скрывается за доменом.
```bash
host google.com
# или
nslookup google.com
```

### 3. Строим Load Balancer
Макет High Availability системы в Docker Compose. Два "глупых" сервера и один Nginx.

`docker-compose.yml`:
```yaml
version: '3'
services:
  # Бэкенд 1
  app1:
    image: hashicorp/http-echo
    command: -text="Answer from SERVER 1"
  # Бэкенд 2
  app2:
    image: hashicorp/http-echo
    command: -text="Answer from SERVER 2"
  # Балансировщик
  nginx:
    image: nginx:alpine
    ports: ["80:80"]
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
```
А в `nginx.conf` мы пропишем `upstream backend { server app1:5678; server app2:5678; }`.
