# День 4. Сети и Масштабирование

[tools] [devops] [network] [nginx]

Работа DevOps-инженера часто сводится к одному: обеспечить доставку сетевого пакета из точки А в точку Б. Когда сайт "не работает", в 90% случаев проблема кроется в том, что где-то на пути от пользователя до базы данных пакет встретил закрытую дверь.
Понимание того, как течет "цифровая кровь" по венам интернета, отличает инженера от "эникейщика".

---

## Путешествие Пакнета

Давайте демистифицируем стек TCP/IP, используя простую аналогию с многоквартирным домом.

1.  **IP-адрес (Дом)**. Это уникальный адрес здания в городе (интернете). `192.168.1.5` или `74.125.205.113`. Зная адрес, почтальон может найти здание, но не знает, кому отдать письмо.
2.  **Порт (Квартира)**. Внутри сервера (дома) живут сотни процессов. Веб-сервер Nginx живет в квартире №80 (или 443). База данных MySQL — в №3306. SSH — в №22. Когда вы стучитесь на сервер без указания порта, браузер неявно добавляет ":80". Если вы постучите в пустую квартиру (порт, который никто не слушает), сервер ответит `Connection Refused`.

### Язык общения: TCP vs UDP

Мало найти адресата, нужно с ним договориться.

- **TCP (Transmission Control Protocol)** — это "Заказное письмо с уведомлением о вручении". Вы (Клиент) и Сервер сначала здороваетесь (Handshake):
  - "Привет, я хочу прислать данные" (SYN)
  - "Привет, я готов, присылай" (SYN-ACK)
  - "Отлично, высылаю" (ACK)

  Это гарантирует, что данные дойдут в правильном порядке. Весь веб (HTTP), почта и файлы работают на TCP.

- **UDP** — это "Почтовый голубь" или просто крик в толпу. Вы кидаете пакеты и не ждете ответа. Дошло? Не дошло? Неважно. Зато это очень быстро. Используется там, где потеря пары кадров не критична: Стриминг видео, онлайн-игры, DNS запросы.

### DNS: Телефонная книга

Люди не запоминают IP-адреса. Мы помним `google.com`.
Система **DNS (Domain Name System)** — это распределенная база данных. Когда вы вводите домен, ваш компьютер:

1.  Смотрит в свой кэш.
2.  Спрашивает у роутера.
3.  Спрашивает у провайдера (ISP).
4.  В итоге доходит до корневых серверов интернета.

Типы записей: **A** (Домен → IP), **CNAME** (Псевдоним → Домен).

---

## Масштабирование: Когда один в поле не воин

Представьте, что вы открыли интернет-магазин на одном сервере. Сначала всё хорошо. Но в "Черную пятницу" пришло 100 000 человек. Процессор перегрелся, память кончилась, сервер упал.
У вас два пути:

1.  **Vertical Scaling (Scale Up)**: Купить сервер помощнее. Больше ядер, больше памяти.
    _Проблема_: Это дорого, и есть физический потолок. Вы не можете поставить 1000 терабайт памяти в одну машину.
2.  **Horizontal Scaling (Scale Out)**: Поставить рядом еще 5 таких же дешевых серверов.
    _Проблема_: Пользователь знает только один адрес `myshop.com`. Как распределить запросы?

### Load Balancer (Балансировщик)

Здесь на сцену выходит **Reverse Proxy** (Nginx, HAProxy). Он встает перед вашим кластером серверов. Пользователи идут к нему, а он, как регулировщик, раскидывает запросы по бэкендам.

- **Round Robin**: Первый запрос — первому, второй — второму...
- **Least Connections**: Отправь тому, кто сейчас меньше всего занят.

---

## Практика

### 1. Анатомия запроса c Curl

Браузер скрывает от нас детали. Инженеры используют `curl`.
Посмотрим на "рукопожатие" и заголовки:

```bash
curl -v https://google.com
```

Вы увидите:

- `* Connected to google.com (IP) port 443` — TCP соединение установлено.
- `* ALPN, offering h2` — согласование шифрования TLS (SSL).
- `> GET / HTTP/2` — мы отправили запрос.
- `< HTTP/2 200` — сервер ответил "ОК".

### 2. DNS раскопки

Попробуйте узнать, кто скрывается за доменом.

```bash
host google.com
# или
nslookup google.com
```

Вы увидите несколько IP-адресов. Это и есть примитивная балансировка (DNS Round Robin) — одной записи соответствует много серверов.

### 3. Строим свой Load Balancer

Соберем макет High Availability системы в Docker Compose.
Два "глупых" бэкенда и один умный Nginx.

`docker-compose.yml`:

```yaml
version: "3"
services:
  # Бэкенд 1: Всегда говорит "Я ПЕРВЫЙ"
  app1:
    image: hashicorp/http-echo
    command: -text="Answer from SERVER 1"

  # Бэкенд 2: Всегда говорит "Я ВТОРОЙ"
  app2:
    image: hashicorp/http-echo
    command: -text="Answer from SERVER 2"

  # Nginx как точка входа
  lb:
    image: nginx:latest
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "8080:80"
```

Рядом файл `nginx.conf`:

```nginx
upstream my_cluster {
    server app1:5678; # Внутри сети docker мы обращаемся по именам сервисов
    server app2:5678;
}

server {
    listen 80;
    location / {
        proxy_pass http://my_cluster;
    }
}
```

Запустите (`docker-compose up`) и пообновляйте страницу `localhost:8080`. Ответы будут меняться. Если вы остановите один контейнер (`docker stop ..._app1_...`), Nginx заметит ошибку и перестанет слать туда трафик. Это и есть **Отказоустойчивость**.

---

## Ресурсы

- **[High Performance Browser Networking](https://hpbn.co/)** (Ilya Grigorik) — Абсолютный маст-рид. Книга, которая объясняет, как на самом деле работает веб, от физики радиоволн 4G до заголовков HTTP/3.
- **[How DNS Works](https://howdns.works/)** — Веселый комикс про DNS.
- **[Nginx Admin Guide](https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/)** — Документация по балансировке.
